{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1PuwcEKqXoZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3264dd25-4988-4cff-855d-eb9221e25f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 50 caption pairs\n",
            "Processed 100 caption pairs\n",
            "Processed 150 caption pairs\n",
            "Processed 200 caption pairs\n",
            "Analysis complete. Results saved to caption_analysis_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries for NLP processing, visualization, data handling and typing\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Set, Tuple, Dict, Optional\n",
        "\n",
        "# Loading the English language model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Adding a pipeline component to merge named entities into single tokens\n",
        "nlp.add_pipe(\"merge_entities\")\n",
        "\n",
        "class FineGrainedMetrics:\n",
        "    \"\"\"\n",
        "    A class for evaluating fine-grained matching between original and generated captions.\n",
        "    Provides methods to compare different aspects like color, number, position, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def related_to_noun(doc: spacy.tokens.Doc, attribute: str, noun: str) -> bool:\n",
        "        \"\"\"\n",
        "        Checking if an attribute is grammatically related to a specific noun in the document.\n",
        "\n",
        "        Args:\n",
        "            doc: The spaCy processed document\n",
        "            attribute: The word/text to check for relation\n",
        "            noun: The noun to check relation with\n",
        "\n",
        "        Returns:\n",
        "            bool: True if attribute is related to noun, False otherwise\n",
        "        \"\"\"\n",
        "        # Iterating through all tokens in the document\n",
        "        for token in doc:\n",
        "            # Checking if current token matches the target noun\n",
        "            if token.text == noun:\n",
        "                # Collecting all words in the noun's syntactic subtree\n",
        "                subtree_words = [t.text for t in token.subtree]\n",
        "                # Verifying if the attribute appears in the subtree\n",
        "                if attribute in subtree_words:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    @classmethod\n",
        "    def color(cls, meta: spacy.tokens.Doc, orig: spacy.tokens.Doc, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Comparing color attributes between original and generated captions.\n",
        "\n",
        "        Args:\n",
        "            meta: Processed generated caption\n",
        "            orig: Processed original caption\n",
        "            generated_nouns: Set of nouns that appear in both captions\n",
        "\n",
        "        Returns:\n",
        "            float: Matching score (0-1), or -1 if no colors in original\n",
        "        \"\"\"\n",
        "        # Defining a set of common color terms for comparison\n",
        "        COLORS = {\n",
        "            'red', 'blue', 'green', 'yellow', 'black', 'white', 'gray', 'grey',\n",
        "            'orange', 'pink', 'purple', 'brown', 'violet', 'indigo',\n",
        "            'turquoise', 'cyan', 'magenta'\n",
        "        }\n",
        "\n",
        "        # Initializing score counter and storage for original colors\n",
        "        color_score = 0.0\n",
        "        original_colors = set()\n",
        "\n",
        "        # Checking color attributes for each common noun\n",
        "        for noun in generated_nouns:\n",
        "            # Finding color adjectives related to current noun in generated caption\n",
        "            meta_colors = {\n",
        "                token.text for token in meta\n",
        "                if (cls.related_to_noun(meta, token.text, noun) and\n",
        "                    token.dep_ in {'acomp', 'amod'} and\n",
        "                    token.text.lower() in COLORS)\n",
        "            }\n",
        "\n",
        "            # Finding color adjectives related to current noun in original caption\n",
        "            orig_colors = {\n",
        "                token.text for token in orig\n",
        "                if (cls.related_to_noun(orig, token.text, noun) and\n",
        "                    token.dep_ in {'acomp', 'amod'} and\n",
        "                    token.text.lower() in COLORS)\n",
        "            }\n",
        "\n",
        "            # Adding found colors to the original colors set\n",
        "            original_colors.update(orig_colors)\n",
        "\n",
        "            # Only comparing colors if they exist in the original caption\n",
        "            if orig_colors:\n",
        "                # Counting matching colors between original and generated\n",
        "                color_score += len(orig_colors & meta_colors)\n",
        "\n",
        "        # Returning -1 if no colors were found in original caption\n",
        "        if not original_colors:\n",
        "            return -1\n",
        "\n",
        "        # Calculating final score as ratio of matches to total original colors\n",
        "        return color_score / len(original_colors)\n",
        "\n",
        "    @classmethod\n",
        "    def number(cls, meta: spacy.tokens.Doc, orig: spacy.tokens.Doc, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Comparing numeric quantities between original and generated captions.\n",
        "\n",
        "        Args:\n",
        "            meta: Processed generated caption\n",
        "            orig: Processed original caption\n",
        "            generated_nouns: Set of nouns that appear in both captions\n",
        "\n",
        "        Returns:\n",
        "            float: Matching score (0-1), or -1 if no numbers in original\n",
        "        \"\"\"\n",
        "        # Creating mapping from words to their numeric equivalents\n",
        "        QUANTITY_MAP = {\n",
        "            'a': '1',\n",
        "            'an': '1',\n",
        "            'the': '1',\n",
        "            'one': '1',\n",
        "            'two': '2',\n",
        "            'three': '3',\n",
        "            'couple': '2',\n",
        "            'few': '3',\n",
        "            'several': '4',\n",
        "            'many': '5',\n",
        "            'dozen': '12'\n",
        "        }\n",
        "\n",
        "        # Initializing score counter and storage for original numbers\n",
        "        number_score = 0.0\n",
        "        original_numbers = set()\n",
        "\n",
        "        # Checking numeric quantities for each common noun\n",
        "        for noun in generated_nouns:\n",
        "            # Finding numeric modifiers in generated caption\n",
        "            meta_nums = {\n",
        "                QUANTITY_MAP.get(token.text.lower(), token.text)\n",
        "                for token in meta\n",
        "                if (cls.related_to_noun(meta, token.text, noun) and\n",
        "                    token.dep_ in {'nummod', 'det'})\n",
        "            }\n",
        "\n",
        "            # Finding numeric modifiers in original caption\n",
        "            orig_nums = {\n",
        "                QUANTITY_MAP.get(token.text.lower(), token.text)\n",
        "                for token in orig\n",
        "                if (cls.related_to_noun(orig, token.text, noun) and\n",
        "                    token.dep_ in {'nummod', 'det'})\n",
        "            }\n",
        "\n",
        "            # Adding found numbers to the original numbers set\n",
        "            original_numbers.update(orig_nums)\n",
        "\n",
        "            # Only comparing numbers if they exist in the original caption\n",
        "            if orig_nums:\n",
        "                # Counting matching numbers between original and generated\n",
        "                number_score += len(orig_nums & meta_nums)\n",
        "\n",
        "        # Returning -1 if no numbers were found in original caption\n",
        "        if not original_numbers:\n",
        "            return -1\n",
        "\n",
        "        # Calculating final score as ratio of matches to total original numbers\n",
        "        return number_score / len(original_numbers)\n",
        "\n",
        "    @classmethod\n",
        "    def text(cls, meta: spacy.tokens.Doc, orig: spacy.tokens.Doc, _: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Comparing quoted text between original and generated captions.\n",
        "\n",
        "        Args:\n",
        "            meta: Processed generated caption\n",
        "            orig: Processed original caption\n",
        "            _: Ignored (for interface consistency)\n",
        "\n",
        "        Returns:\n",
        "            float: Matching score (0-1), or -1 if no text in original\n",
        "        \"\"\"\n",
        "        # Defining indicators that text might follow in the caption\n",
        "        TEXT_INDICATORS = {'written', 'saying', 'says', 'reading', 'text'}\n",
        "        # Creating pattern to match quoted text segments\n",
        "        QUOTE_PATTERN = r'[\\\"\\'«»“”]([^\\\"\\'«»“”]*)[\\\"\\'«»“”]'\n",
        "\n",
        "        # Checking if original caption contains any text indicators\n",
        "        has_text_indicator = any(token.text in TEXT_INDICATORS for token in orig)\n",
        "\n",
        "        # Proceeding only if text indicators are present\n",
        "        if has_text_indicator:\n",
        "            # Finding all quoted segments in both captions\n",
        "            orig_matches = re.findall(QUOTE_PATTERN, orig.text)\n",
        "            meta_matches = re.findall(QUOTE_PATTERN, meta.text)\n",
        "\n",
        "            # Returning -1 if no quoted text found in original\n",
        "            if not orig_matches:\n",
        "                return -1\n",
        "\n",
        "            # Normalizing text by removing spaces and converting to lowercase\n",
        "            orig_normalized = [''.join(s.lower().split()) for s in orig_matches]\n",
        "            meta_normalized = [''.join(s.lower().split()) for s in meta_matches]\n",
        "\n",
        "            # Counting matches between original and generated quoted text\n",
        "            matches = 0\n",
        "            for orig_text in orig_normalized:\n",
        "                if any(orig_text in meta_text for meta_text in meta_normalized):\n",
        "                    matches += 1\n",
        "\n",
        "            # Calculating score as ratio of matches to total original quotes\n",
        "            return matches / len(orig_matches)\n",
        "\n",
        "        return -1\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_spatial_relations(doc: spacy.tokens.Doc) -> Set[Tuple[str, str, str]]:\n",
        "        \"\"\"\n",
        "        Extracting spatial relationships as (subject, preposition, object) tuples.\n",
        "\n",
        "        Args:\n",
        "            doc: Processed spaCy document\n",
        "\n",
        "        Returns:\n",
        "            Set of (subject, relation, object) tuples\n",
        "        \"\"\"\n",
        "        relations = set()\n",
        "\n",
        "        # Analyzing each token in the document\n",
        "        for token in doc:\n",
        "            # Looking for prepositional phrases\n",
        "            if token.dep_ == 'prep':\n",
        "                # Finding prepositional objects\n",
        "                pobjects = [child for child in token.children if child.dep_ == 'pobj']\n",
        "\n",
        "                if pobjects:\n",
        "                    pobject = pobjects[0].text\n",
        "                    # Initializing subject as None before searching\n",
        "                    subject = None\n",
        "\n",
        "                    # Checking ancestors to find the related subject\n",
        "                    for ancestor in token.ancestors:\n",
        "                        if ancestor.dep_ in {'nsubj', 'nsubjpass', 'dobj', 'pobj'}:\n",
        "                            subject = ancestor.text\n",
        "                            break\n",
        "\n",
        "                    # Checking for compound nouns if no subject found yet\n",
        "                    if subject is None and token.head.dep_ == 'compound':\n",
        "                        subject = token.head.text\n",
        "\n",
        "                    # Adding relation if subject was found\n",
        "                    if subject:\n",
        "                        relations.add((subject, token.text, pobject))\n",
        "\n",
        "        return relations\n",
        "\n",
        "    @classmethod\n",
        "    def position(cls, meta: spacy.tokens.Doc, orig: spacy.tokens.Doc, _: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Comparing spatial relationships between original and generated captions.\n",
        "\n",
        "        Args:\n",
        "            meta: Processed generated caption\n",
        "            orig: Processed original caption\n",
        "            _: Ignored (for interface consistency)\n",
        "\n",
        "        Returns:\n",
        "            float: Matching score (0-1), or -1 if no positions in original\n",
        "        \"\"\"\n",
        "        # Extracting spatial relations from both captions\n",
        "        orig_relations = cls.extract_spatial_relations(orig)\n",
        "        meta_relations = cls.extract_spatial_relations(meta)\n",
        "\n",
        "        # Returning -1 if no spatial relations in original\n",
        "        if not orig_relations:\n",
        "            return -1\n",
        "\n",
        "        # Calculating matching relations between original and generated\n",
        "        matches = orig_relations & meta_relations\n",
        "        # Returning score as ratio of matches to total original relations\n",
        "        return len(matches) / len(orig_relations)\n",
        "\n",
        "    @classmethod\n",
        "    def shape(cls, meta: spacy.tokens.Doc, orig: spacy.tokens.Doc, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Comparing shape descriptions between original and generated captions.\n",
        "\n",
        "        Args:\n",
        "            meta: Processed generated caption\n",
        "            orig: Processed original caption\n",
        "            generated_nouns: Set of nouns that appear in both captions\n",
        "\n",
        "        Returns:\n",
        "            float: Matching score (0-1), or -1 if no shapes in original\n",
        "        \"\"\"\n",
        "        # Defining set of common shape descriptors\n",
        "        SHAPES = {\n",
        "            'circular', 'round', 'square', 'triangular', 'rectangular',\n",
        "            'oval', 'hexagonal', 'pentagonal', 'octagonal', 'spherical',\n",
        "            'cubical', 'cylindrical', 'conical', 'pyramidal', 'flat', 'curved'\n",
        "        }\n",
        "\n",
        "        # Initializing score counter and storage for original shapes\n",
        "        shape_score = 0.0\n",
        "        original_shapes = set()\n",
        "\n",
        "        # Checking shape descriptions for each common noun\n",
        "        for noun in generated_nouns:\n",
        "            # Finding shape adjectives in generated caption\n",
        "            meta_shapes = {\n",
        "                token.text for token in meta\n",
        "                if (cls.related_to_noun(meta, token.text, noun) and\n",
        "                    token.dep_ in {'acomp', 'amod'} and\n",
        "                    token.text.lower() in SHAPES)\n",
        "            }\n",
        "\n",
        "            # Finding shape adjectives in original caption\n",
        "            orig_shapes = {\n",
        "                token.text for token in orig\n",
        "                if (cls.related_to_noun(orig, token.text, noun) and\n",
        "                    token.dep_ in {'acomp', 'amod'} and\n",
        "                    token.text.lower() in SHAPES)\n",
        "            }\n",
        "\n",
        "            # Adding found shapes to the original shapes set\n",
        "            original_shapes.update(orig_shapes)\n",
        "\n",
        "            # Counting matching shapes if they exist in original\n",
        "            if orig_shapes:\n",
        "                shape_score += len(orig_shapes & meta_shapes)\n",
        "\n",
        "        # Returning -1 if no shapes were found in original\n",
        "        if not original_shapes:\n",
        "            return -1\n",
        "\n",
        "        # Calculating final score as ratio of matches to total original shapes\n",
        "        return shape_score / len(original_shapes)\n",
        "\n",
        "\n",
        "def analyze_caption_pair(meta_caption: str, orig_caption: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Analyzing a pair of captions (original and generated) across multiple dimensions.\n",
        "\n",
        "    Args:\n",
        "        meta_caption: The generated caption text\n",
        "        orig_caption: The original prompt text\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all metrics and their scores\n",
        "    \"\"\"\n",
        "    # Processing both captions with spaCy NLP pipeline\n",
        "    meta_doc = nlp(meta_caption)\n",
        "    orig_doc = nlp(orig_caption)\n",
        "\n",
        "    # Extracting nouns and proper nouns from both captions\n",
        "    meta_nouns = {token.text for token in meta_doc if token.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "    orig_nouns = {token.text for token in orig_doc if token.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "\n",
        "    # Calculating noun recall score\n",
        "    noun_recall = len(orig_nouns & meta_nouns) / len(orig_nouns) if orig_nouns else 0\n",
        "    # Identifying missing nouns from generated caption\n",
        "    missing_nouns = orig_nouns - meta_nouns\n",
        "    # Finding common nouns between both captions\n",
        "    common_nouns = orig_nouns & meta_nouns\n",
        "\n",
        "    # Calculating all fine-grained metrics\n",
        "    metrics = {\n",
        "        'noun_recall': noun_recall,\n",
        "        'missing_nouns': list(missing_nouns),\n",
        "        'color': FineGrainedMetrics.color(meta_doc, orig_doc, common_nouns),\n",
        "        'number': FineGrainedMetrics.number(meta_doc, orig_doc, common_nouns),\n",
        "        'text': FineGrainedMetrics.text(meta_doc, orig_doc, common_nouns),\n",
        "        'position': FineGrainedMetrics.position(meta_doc, orig_doc, common_nouns),\n",
        "        'shape': FineGrainedMetrics.shape(meta_doc, orig_doc, common_nouns)\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function to process all caption pairs.\"\"\"\n",
        "    # Defining target categories for analysis\n",
        "    target_categories = ['Colors', 'Positional', 'Counting', 'Descriptions']\n",
        "    # Loading generated captions and original prompts datasets\n",
        "    sdxl_captions = pd.read_csv('meta_captions_sdxl.csv')\n",
        "    prompt_df = pd.read_csv('DrawBenchPrompts.csv')\n",
        "    # Filtering prompts to only include target categories\n",
        "    prompt_df = prompt_df.loc[prompt_df['Category'].isin(target_categories)].reset_index()\n",
        "\n",
        "    # Initializing list to store analysis results\n",
        "    results = []\n",
        "\n",
        "    # Processing each caption pair in the dataset\n",
        "    for _, row in sdxl_captions.iterrows():\n",
        "        # Analyzing current caption pair\n",
        "        metrics = analyze_caption_pair(row['Meta Caption'], row['Prompts'])\n",
        "        # Adding additional metadata to results\n",
        "        metrics.update({\n",
        "            'category': row['Category'],\n",
        "            'original_prompt': row['Prompts'],\n",
        "            'generated_caption': row['Meta Caption']\n",
        "        })\n",
        "        results.append(metrics)\n",
        "\n",
        "        # Printing progress every 50 processed pairs\n",
        "        if len(results) % 50 == 0:\n",
        "            print(f\"Processed {len(results)} caption pairs\")\n",
        "\n",
        "    # Converting results to DataFrame and saving to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('caption_analysis_results.csv', index=False)\n",
        "    print(\"Analysis complete. Results saved to caption_analysis_results.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries for data analysis and numerical operations\n",
        "import pandas as pd\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "def analyze_drawbench_vs_metacaptions(drawbench_csv: str, metacaptions_csv: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Comparing DrawBench prompts with their corresponding Meta Captions using fine-grained metrics.\n",
        "\n",
        "    Args:\n",
        "        drawbench_csv: Path to DrawBench prompts CSV\n",
        "        metacaptions_csv: Path to Meta Captions CSV\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of average metric scores across all comparisons\n",
        "    \"\"\"\n",
        "    # Loading both datasets into pandas DataFrames\n",
        "    drawbench = pd.read_csv(drawbench_csv)\n",
        "    metacaptions = pd.read_csv(metacaptions_csv)\n",
        "\n",
        "    # Merging datasets on the 'Prompts' column to align matching pairs\n",
        "    merged = pd.merge(drawbench, metacaptions,\n",
        "                     left_on='Prompts', right_on='Prompts',\n",
        "                     how='inner', suffixes=('_db', '_meta'))\n",
        "\n",
        "    # Initializing dictionary to store metric values for each comparison\n",
        "    metrics = {\n",
        "        'Object_FtG': [],\n",
        "        'Colour_FtG': [],\n",
        "        'Number_FtG': [],\n",
        "        'Positional_FtG': [],\n",
        "        'Text_FtG': []\n",
        "    }\n",
        "\n",
        "    # Processing each prompt-caption pair in the merged dataset\n",
        "    for _, row in merged.iterrows():\n",
        "        # Processing both texts with spaCy's NLP pipeline\n",
        "        meta_doc = nlp(row['Meta Caption'])\n",
        "        orig_doc = nlp(row['Prompts'])\n",
        "\n",
        "        # Stage 1: Calculating noun recall (Object Fine-to-Grained metric)\n",
        "        meta_nouns = {t.text for t in meta_doc if t.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "        orig_nouns = {t.text for t in orig_doc if t.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "        # Computing recall as ratio of matching nouns to original nouns\n",
        "        noun_recall = len(orig_nouns & meta_nouns) / len(orig_nouns) if orig_nouns else 0\n",
        "        metrics['Object_FtG'].append(noun_recall)\n",
        "\n",
        "        # Stage 2: Calculating fine-grained metrics for shared nouns\n",
        "        common_nouns = orig_nouns & meta_nouns\n",
        "        metrics['Colour_FtG'].append(FineGrainedMetrics.color(meta_doc, orig_doc, common_nouns))\n",
        "        metrics['Number_FtG'].append(FineGrainedMetrics.number(meta_doc, orig_doc, common_nouns))\n",
        "        metrics['Positional_FtG'].append(FineGrainedMetrics.position(meta_doc, orig_doc, common_nouns))\n",
        "        metrics['Text_FtG'].append(FineGrainedMetrics.text(meta_doc, orig_doc, common_nouns))\n",
        "\n",
        "    # Calculating average scores while handling -1 (non-applicable cases)\n",
        "    results = {}\n",
        "    for metric, values in metrics.items():\n",
        "        # Filtering out non-applicable (-1) values\n",
        "        valid_values = [v for v in values if v != -1]\n",
        "        # Converting to percentage and storing, or marking as N/A if no valid values\n",
        "        results[metric] = np.mean(valid_values) * 100 if valid_values else \"N/A\"\n",
        "\n",
        "    return results\n",
        "\n",
        "def format_results_table(results: Dict[str, float]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Formatting the analysis results into a table matching the reference style.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of metric scores\n",
        "\n",
        "    Returns:\n",
        "        Formatted DataFrame with one row showing the comparison\n",
        "    \"\"\"\n",
        "    # Creating multi-level column structure for the results table\n",
        "    columns = pd.MultiIndex.from_tuples([\n",
        "        ('DrawBench vs MetaCaptions', 'Stage-1', 'Object FtG'),\n",
        "        ('DrawBench vs MetaCaptions', 'Stage-2', 'Colour FtG'),\n",
        "        ('DrawBench vs MetaCaptions', 'Stage-2', 'Number FtG'),\n",
        "        ('DrawBench vs MetaCaptions', 'Stage-2', 'Positional FtG'),\n",
        "        ('DrawBench vs MetaCaptions', 'Stage-2', 'Text FtG')\n",
        "    ])\n",
        "\n",
        "    # Creating DataFrame with formatted percentage values\n",
        "    df = pd.DataFrame([[\n",
        "        f\"{results.get('Object_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Colour_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Number_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Positional_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Text_FtG', 'N/A'):.2f}\"\n",
        "    ]], columns=columns, index=['SDXL'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Defining paths to input CSV files\n",
        "    drawbench_path = \"DrawBenchPrompts.csv\"\n",
        "    metacaptions_path = \"meta_captions_sdxl.csv\"\n",
        "\n",
        "    # Running the comparison analysis\n",
        "    comparison_results = analyze_drawbench_vs_metacaptions(drawbench_path, metacaptions_path)\n",
        "\n",
        "    # Formatting results into table structure\n",
        "    results_table = format_results_table(comparison_results)\n",
        "\n",
        "    # Displaying and saving results\n",
        "    print(\"Comparison Results:\")\n",
        "    print(results_table)\n",
        "    # Saving results to CSV file\n",
        "    results_table.to_csv(\"drawbench_metacaptions_comparison.csv\")\n",
        "    print(\"\\nResults saved to drawbench_metacaptions_comparison.csv\")"
      ],
      "metadata": {
        "id": "SeBia9moa9id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfc5ba6-88f7-4feb-8573-e1fd091f3f88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Results:\n",
            "     DrawBench vs MetaCaptions                                              \n",
            "                       Stage-1    Stage-2                                   \n",
            "                    Object FtG Colour FtG Number FtG Positional FtG Text FtG\n",
            "SDXL                     35.67      72.73     111.07           0.00    23.81\n",
            "\n",
            "Results saved to drawbench_metacaptions_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "# Creating a table for results\n",
        "def display_tabulated_results(results: Dict[str, float]):\n",
        "    headers = [\n",
        "        \"Stage-1: Object FtG\",\n",
        "        \"Stage-2: Colour FtG\",\n",
        "        \"Stage-2: Number FtG\",\n",
        "        \"Stage-2: Positional FtG\",\n",
        "        \"Stage-2: Text FtG\"\n",
        "    ]\n",
        "\n",
        "    row = [\n",
        "        f\"{results.get('Object_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Colour_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Number_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Positional_FtG', 'N/A'):.2f}\",\n",
        "        f\"{results.get('Text_FtG', 'N/A'):.2f}\"\n",
        "    ]\n",
        "\n",
        "    table = tabulate([row], headers=headers, tablefmt=\"grid\", showindex=[\"SDXL\"])\n",
        "    print(\"\\n Comparison Table:\\n\")\n",
        "    print(table)\n",
        "\n",
        "# After getting results:\n",
        "display_tabulated_results(comparison_results)\n"
      ],
      "metadata": {
        "id": "LQUYuxu-iRdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd95e775-68e6-48a4-b821-68a77b00f6d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Comparison Table:\n",
            "\n",
            "+------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------+\n",
            "|      |   Stage-1: Object FtG |   Stage-2: Colour FtG |   Stage-2: Number FtG |   Stage-2: Positional FtG |   Stage-2: Text FtG |\n",
            "+======+=======================+=======================+=======================+===========================+=====================+\n",
            "| SDXL |                 35.67 |                 72.73 |                111.07 |                         0 |               23.81 |\n",
            "+------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------+\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone GroundingDINO\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "!pip install -e GroundingDINO\n",
        "\n",
        "# Other dependencies\n",
        "!pip install supervision diffusers transformers accelerate scipy safetensors\n",
        "!pip install huggingface_hub tqdm pandas\n"
      ],
      "metadata": {
        "id": "3zDcnyY_615-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXWqioXh6eiF",
        "outputId": "9f70de98-ccd9-4e09-a794-5615cd4d712f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final text_encoder_type: bert-base-uncased\n",
            "Model loaded from /root/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
            "\n",
            "1.jpeg bounding boxes:\n",
            "\n",
            "2.jpeg bounding boxes:\n",
            "\n",
            "3.jpeg bounding boxes:\n",
            "\n",
            "4.jpeg bounding boxes:\n",
            "\n",
            "5.jpeg bounding boxes:\n",
            "\n",
            "Total time for 5 images: 165.25 seconds\n",
            "Throughput: 0.03 images per second\n"
          ]
        }
      ],
      "source": [
        "# ===================================================\n",
        "# GroundingDINO Inference for Local Images (CPU-friendly version)\n",
        "# ===================================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Add GroundingDINO repo to path ---\n",
        "sys.path.append(\"GroundingDINO\")  # adjust if your repo is elsewhere\n",
        "\n",
        "# --- GroundingDINO core imports ---\n",
        "from GroundingDINO.groundingdino.util.slconfig import SLConfig\n",
        "from GroundingDINO.groundingdino.models import build_model\n",
        "from GroundingDINO.groundingdino.util.utils import clean_state_dict\n",
        "from GroundingDINO.groundingdino.util.inference import load_image, predict\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# ----------------------\n",
        "# Load model manually\n",
        "# ----------------------\n",
        "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
        "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
        "    args = SLConfig.fromfile(cache_config_file)\n",
        "    model = build_model(args)\n",
        "    args.device = device\n",
        "\n",
        "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
        "    log = model.load_state_dict(clean_state_dict(checkpoint[\"model\"]), strict=False)\n",
        "    print(f\"Model loaded from {cache_file} => {log}\")\n",
        "    _ = model.eval()\n",
        "    return model\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Configuration\n",
        "# -----------------------------------------------------------\n",
        "DEVICE = torch.device(\"cpu\")  # Force CPU\n",
        "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
        "ckpt_filename = \"groundingdino_swinb_cogcoor.pth\"\n",
        "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
        "\n",
        "IMAGE_FOLDER = \"Img_folder\"  # folder containing 1.jpeg to 5.jpeg\n",
        "TEXT_PROMPT = \"\"  # empty = detect all\n",
        "BOX_THRESHOLD = 0.3\n",
        "TEXT_THRESHOLD = 0.25\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Load model\n",
        "# -----------------------------------------------------------\n",
        "model = load_model_hf(\n",
        "    repo_id=ckpt_repo_id,\n",
        "    filename=ckpt_filename,\n",
        "    ckpt_config_filename=ckpt_config_filename,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Inference function\n",
        "# -----------------------------------------------------------\n",
        "def get_boxes(image_path):\n",
        "    image_source, image = load_image(image_path)\n",
        "    boxes, _, _ = predict(\n",
        "        model=model,\n",
        "        image=image,\n",
        "        caption=TEXT_PROMPT,\n",
        "        box_threshold=BOX_THRESHOLD,\n",
        "        text_threshold=TEXT_THRESHOLD,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "    # Scale boxes to original image size\n",
        "    boxes = boxes * torch.tensor([\n",
        "        image_source.shape[1], image_source.shape[0],\n",
        "        image_source.shape[1], image_source.shape[0]\n",
        "    ])\n",
        "\n",
        "    # Convert [x1, y1, x2, y2] â†’ [x_center, y_center, width, height]\n",
        "    boxes_xywh = []\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box.tolist()\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        xc = x1 + w / 2\n",
        "        yc = y1 + h / 2\n",
        "        boxes_xywh.append([xc, yc, w, h])\n",
        "\n",
        "    return boxes_xywh\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Run on images in folder\n",
        "# -----------------------------------------------------------\n",
        "image_names = [f\"{i}.jpeg\" for i in range(1, 6)]\n",
        "start_time = time.time()\n",
        "\n",
        "for img_name in image_names:\n",
        "    img_path = os.path.join(IMAGE_FOLDER, img_name)\n",
        "    try:\n",
        "        boxes = get_boxes(img_path)\n",
        "        print(f\"\\n{img_name} bounding boxes:\")\n",
        "        for box in boxes:\n",
        "            x, y, w, h = box\n",
        "            print(f\"  [{x:.1f}, {y:.1f}, {w:.1f}, {h:.1f}]\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {img_name}: {e}\")\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "throughput = len(image_names) / total_time\n",
        "\n",
        "print(f\"\\nTotal time for {len(image_names)} images: {total_time:.2f} seconds\")\n",
        "print(f\"Throughput: {throughput:.2f} images per second\")\n"
      ]
    }
  ]
}
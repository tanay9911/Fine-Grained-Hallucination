{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c0a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config for api key\n",
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "989bde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = f\"/Users/dhirendrachoudhary/Desktop/Workstation/Research/APIGenie/data/config.json\"\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "\n",
    "api_key = config['llm_api']['api_key']\n",
    "model_name = config['llm_api']['model_name']\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b25ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_captions = pd.read_csv('image_captions.csv')\n",
    "sdxl_dataset_path = 'sdxl_outputs'\n",
    "sd_2_dataset_path = 'sd_2_outputs'\n",
    "sdxl_mask_path = os.path.join(sdxl_dataset_path, 'masks')\n",
    "sd_2_mask_path = os.path.join(sd_2_dataset_path, 'masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa91b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(mask):\n",
    "    mask_array = np.array(mask)\n",
    "    mask_coordinates = np.column_stack(np.where(mask_array > 0))\n",
    "    if len(mask_coordinates) == 0:\n",
    "        centroid = (None, None)\n",
    "    else:\n",
    "        # Calculate the median of the coordinates\n",
    "        centroid = np.mean(mask_coordinates, axis=0)\n",
    "        centroid = centroid[1], centroid[0]\n",
    "    return tuple(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb96554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sdxl_dataset_path, image_name)\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m----> 7\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdxl_mask_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sdxl_mask_path, mask_dir)\n\u001b[1;32m      9\u001b[0m dense_captions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for image_name in tqdm(os.listdir(sdxl_dataset_path)):\n",
    "    if not image_name.endswith('jpg'):\n",
    "        continue\n",
    "    idx = int(image_name.split('.')[0])\n",
    "    image_path = os.path.join(sdxl_dataset_path, image_name)\n",
    "    img = Image.open(image_path)\n",
    "    mask_dir = [i for i in os.listdir(sdxl_mask_path) if idx==int(i.split('-')[0])][0]\n",
    "    mask_dir = os.path.join(sdxl_mask_path, mask_dir)\n",
    "    dense_captions = []\n",
    "    for root, nouns, masks in os.walk(mask_dir):\n",
    "        for mask in masks:\n",
    "            mask_path = os.path.join(root, mask)\n",
    "            mask = Image.open(mask_path)\n",
    "            centroid = get_centroid(mask)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff66b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-1.5-flash'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"I am providing you with captions for sub-regions of an image. These captions will be provided by the corresponding centroids\n",
    "for the objects in the sub-regions. I want you to stitch all the dense captions into one unified caption for the entire image.\n",
    "You have to use the centroid information to deduce the relative positions of each of the objects. Do not add any new information\n",
    "to the captions. Make the caption as short as possible without losing too many details. Any mention of a black background should be ignored. Do not hallucinate any details. Generate the final caption within the <caption></caption> tags.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a meta image captioning model. You look at various sub-captions and create a meaningful grounded caption using those. You can  use additional provided information to facilitate spatial reasoning.\"),\n",
    "    contents=\"Hello there\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddcb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

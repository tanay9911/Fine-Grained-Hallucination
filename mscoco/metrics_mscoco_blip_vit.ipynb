{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "from typing import Set, Dict, List, Tuple\n",
        "\n",
        "# Loading the English language model with entity recognition capabilities\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Enhancing the pipeline to merge recognized entities into single tokens\n",
        "nlp.add_pipe(\"merge_entities\")\n",
        "\n",
        "class FineGrainedMetrics:\n",
        "    \"\"\"\n",
        "    Implementing the fine-grained evaluation metrics as specified in the original paper.\n",
        "    The class provides methods for comparing various linguistic aspects between captions.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def related_to_noun(cls, doc, attr: str, noun: str) -> bool:\n",
        "        \"\"\"\n",
        "        Determining if a given attribute is grammatically associated with a specific noun.\n",
        "        Examining the syntactic subtree of each noun occurrence to verify attribute relationships.\n",
        "        \"\"\"\n",
        "        for token in doc:\n",
        "            if token.text == noun:\n",
        "                subtree = [t.text for t in token.subtree]\n",
        "                if attr in subtree:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    @classmethod\n",
        "    def colour(cls, meta, orig, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Calculating color attribute matching between original and generated captions.\n",
        "        Processing all nouns present in both captions and comparing associated color adjectives.\n",
        "        Returning -1 when no color attributes exist in the original caption.\n",
        "        \"\"\"\n",
        "        colours = {\n",
        "            'red', 'blue', 'green', 'yellow', 'black', 'white', 'gray', 'grey',\n",
        "            'orange', 'pink', 'purple', 'brown', 'violet', 'indigo',\n",
        "            'turquoise', 'cyan', 'magenta'\n",
        "        }\n",
        "        colour_avg = 0.\n",
        "        orig_colour_set = set()\n",
        "\n",
        "        for noun in generated_nouns:\n",
        "            meta_adjectives = {\n",
        "                token.text for token in meta\n",
        "                if cls.related_to_noun(meta, token.text, noun)\n",
        "                and token.dep_ in ['acomp', 'amod']\n",
        "            }\n",
        "            orig_adjectives = {\n",
        "                token.text for token in orig\n",
        "                if cls.related_to_noun(orig, token.text, noun)\n",
        "                and token.dep_ in ['acomp', 'amod']\n",
        "            }\n",
        "\n",
        "            meta_colours = colours.intersection(meta_adjectives)\n",
        "            orig_colours = colours.intersection(orig_adjectives)\n",
        "            orig_colour_set.update(orig_colours)\n",
        "\n",
        "            if orig_colours:\n",
        "                colour_avg += len(orig_colours & meta_colours)\n",
        "\n",
        "        return colour_avg / len(orig_colour_set) if orig_colour_set else -1\n",
        "\n",
        "    @classmethod\n",
        "    def number(cls, meta, orig, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Evaluating numerical quantity matching between captions.\n",
        "        Normalizing textual number representations (e.g., 'a' → '1') before comparison.\n",
        "        Handling both explicit numerals and quantifier words through a mapping dictionary.\n",
        "        \"\"\"\n",
        "        quantities_map = {\n",
        "            'a': '1', 'an': '1', 'the': '1', 'couple': '2',\n",
        "            'dozen': '12', 'one': '1', 'two': '2', 'three': '3'\n",
        "        }\n",
        "        num_avg = 0.\n",
        "        orig_num_set = set()\n",
        "\n",
        "        for noun in generated_nouns:\n",
        "            meta_nums = {\n",
        "                quantities_map.get(token.text.lower(), token.text)\n",
        "                for token in meta\n",
        "                if cls.related_to_noun(meta, token.text, noun)\n",
        "                and token.dep_ in ['nummod', 'det']\n",
        "            }\n",
        "            orig_nums = {\n",
        "                quantities_map.get(token.text.lower(), token.text)\n",
        "                for token in orig\n",
        "                if cls.related_to_noun(orig, token.text, noun)\n",
        "                and token.dep_ in ['nummod', 'det']\n",
        "            }\n",
        "\n",
        "            orig_num_set.update(orig_nums)\n",
        "            if orig_nums:\n",
        "                num_avg += len(orig_nums & meta_nums)\n",
        "\n",
        "        return num_avg / len(orig_num_set) if orig_num_set else -1\n",
        "\n",
        "    @classmethod\n",
        "    def text(cls, meta, orig, _) -> float:\n",
        "        \"\"\"\n",
        "        Assessing text/quote matching between captions.\n",
        "        Identifying quoted segments when preceded by specific indicator words.\n",
        "        Implementing case-insensitive comparison after whitespace normalization.\n",
        "        \"\"\"\n",
        "        indicators = {'written', 'saying', 'says', 'reading', 'text'}\n",
        "        pattern = r'[\\\"\\'«»\"]([^\\\"\\'«»\"]*)[\\\"\\'«»\"]'\n",
        "\n",
        "        if any(token.text in indicators for token in orig):\n",
        "            orig_matches = re.findall(pattern, orig.text)\n",
        "            meta_matches = re.findall(pattern, meta.text)\n",
        "\n",
        "            if not orig_matches:\n",
        "                return -1\n",
        "\n",
        "            orig_normalized = [''.join(s.lower().split()) for s in orig_matches]\n",
        "            meta_normalized = [''.join(s.lower().split()) for s in meta_matches]\n",
        "\n",
        "            matches = sum(\n",
        "                1 for orig_text in orig_normalized\n",
        "                if any(orig_text in meta_text for meta_text in meta_normalized)\n",
        "            )\n",
        "            return matches / len(orig_matches)\n",
        "        return -1\n",
        "\n",
        "    @classmethod\n",
        "    def extract_triplets(cls, doc) -> Set[Tuple[str, str, str]]:\n",
        "        \"\"\"\n",
        "        Extracting spatial relationships as subject-preposition-object triplets.\n",
        "        Analyzing dependency parse trees to identify prepositional phrases and their governors.\n",
        "        \"\"\"\n",
        "        triplets = set()\n",
        "        for token in doc:\n",
        "            if token.dep_ == 'prep':\n",
        "                pobjects = [child for child in token.children if child.dep_ == 'pobj']\n",
        "                if pobjects:\n",
        "                    subject = None\n",
        "                    for ancestor in token.ancestors:\n",
        "                        if ancestor.dep_ in ['nsubj', 'nsubjpass']:\n",
        "                            subject = ancestor.text\n",
        "                            break\n",
        "                    if subject:\n",
        "                        triplets.add((subject, token.text, pobjects[0].text))\n",
        "        return triplets\n",
        "\n",
        "    @classmethod\n",
        "    def position(cls, meta, orig, _) -> float:\n",
        "        \"\"\"\n",
        "        Computing positional relationship matching using extracted triplets.\n",
        "        Comparing spatial relations between original and generated captions.\n",
        "        Only evaluating when spatial relations exist in the original caption.\n",
        "        \"\"\"\n",
        "        orig_triplets = cls.extract_triplets(orig)\n",
        "        meta_triplets = cls.extract_triplets(meta)\n",
        "\n",
        "        if not orig_triplets:\n",
        "            return -1\n",
        "        return len(orig_triplets & meta_triplets) / len(orig_triplets)\n",
        "\n",
        "    @classmethod\n",
        "    def shape(cls, meta, orig, generated_nouns: Set[str]) -> float:\n",
        "        \"\"\"\n",
        "        Evaluating shape attribute matching for shared nouns.\n",
        "        Utilizing a predefined vocabulary of shape descriptors.\n",
        "        Considering only adjectives grammatically connected to the target nouns.\n",
        "        \"\"\"\n",
        "        shapes = {\n",
        "            'circular', 'round', 'square', 'triangular', 'rectangular',\n",
        "            'oval', 'hexagonal', 'pentagonal', 'octagonal', 'spherical',\n",
        "            'cubical', 'cylindrical', 'conical', 'pyramidal', 'flat', 'curved'\n",
        "        }\n",
        "        shape_avg = 0.\n",
        "        orig_shape_set = set()\n",
        "\n",
        "        for noun in generated_nouns:\n",
        "            meta_shapes = {\n",
        "                token.text for token in meta\n",
        "                if cls.related_to_noun(meta, token.text, noun)\n",
        "                and token.dep_ in ['acomp', 'amod']\n",
        "            }\n",
        "            orig_shapes = {\n",
        "                token.text for token in orig\n",
        "                if cls.related_to_noun(orig, token.text, noun)\n",
        "                and token.dep_ in ['acomp', 'amod']\n",
        "            }\n",
        "\n",
        "            meta_filtered = shapes.intersection(meta_shapes)\n",
        "            orig_filtered = shapes.intersection(orig_shapes)\n",
        "            orig_shape_set.update(orig_filtered)\n",
        "\n",
        "            if orig_filtered:\n",
        "                shape_avg += len(orig_filtered & meta_filtered)\n",
        "\n",
        "        return shape_avg / len(orig_shape_set) if orig_shape_set else -1\n",
        "\n",
        "def stage_one_metric(meta, orig):\n",
        "    \"\"\"\n",
        "    Performing first-stage evaluation: noun phrase recall analysis.\n",
        "    Identifying:\n",
        "    1. The proportion of original nouns present in generated caption (recall)\n",
        "    2. Nouns missing from the generated caption\n",
        "    3. Nouns successfully generated (intersection)\n",
        "    \"\"\"\n",
        "    meta_nouns = {token.text for token in meta if token.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "    orig_nouns = {token.text for token in orig if token.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "    non_generated = orig_nouns - meta_nouns\n",
        "    noun_recall = len(orig_nouns & meta_nouns) / len(orig_nouns) if orig_nouns else 0\n",
        "    generated_nouns = orig_nouns & meta_nouns\n",
        "    return noun_recall, non_generated, generated_nouns\n",
        "\n",
        "def stage_two_metric(meta, orig, generated_nouns: Set[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Conducting second-stage fine-grained attribute evaluation.\n",
        "    Computing five specific metrics for the shared nouns:\n",
        "    1. Color adjective matching\n",
        "    2. Numerical quantity matching\n",
        "    3. Text/quote matching\n",
        "    4. Positional relationship matching\n",
        "    5. Shape descriptor matching\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'color': FineGrainedMetrics.colour(meta, orig, generated_nouns),\n",
        "        'number': FineGrainedMetrics.number(meta, orig, generated_nouns),\n",
        "        'text': FineGrainedMetrics.text(meta, orig, generated_nouns),\n",
        "        'position': FineGrainedMetrics.position(meta, orig, generated_nouns),\n",
        "        'shape': FineGrainedMetrics.shape(meta, orig, generated_nouns)\n",
        "    }\n",
        "\n",
        "def process_caption_comparison(input_csv: str, output_csv: str):\n",
        "    \"\"\"\n",
        "    Executing the complete caption evaluation pipeline:\n",
        "    1. Loading and processing the input CSV containing caption pairs\n",
        "    2. Performing linguistic analysis on each caption pair\n",
        "    3. Calculating both stage-one and stage-two metrics\n",
        "    4. Saving comprehensive results to output CSV\n",
        "    5. Generating and displaying average performance metrics\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_csv)\n",
        "    results = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Processing captions through spaCy's NLP pipeline\n",
        "        meta_blip = nlp(row['blip_caption'])\n",
        "        meta_vit = nlp(row['vit_caption'])\n",
        "        orig = nlp(row['mscoco_caption'])\n",
        "\n",
        "        # Evaluating BLIP model performance\n",
        "        blip_recall, blip_missing, blip_nouns = stage_one_metric(meta_blip, orig)\n",
        "        blip_metrics = stage_two_metric(meta_blip, orig, blip_nouns)\n",
        "        results.append({\n",
        "            'image_name': row['image_name'],\n",
        "            'model': 'BLIP',\n",
        "            'noun_recall': blip_recall,\n",
        "            **blip_metrics,\n",
        "            'missing_nouns': ', '.join(blip_missing)\n",
        "        })\n",
        "\n",
        "        # Evaluating ViT model performance\n",
        "        vit_recall, vit_missing, vit_nouns = stage_one_metric(meta_vit, orig)\n",
        "        vit_metrics = stage_two_metric(meta_vit, orig, vit_nouns)\n",
        "        results.append({\n",
        "            'image_name': row['image_name'],\n",
        "            'model': 'ViT',\n",
        "            'noun_recall': vit_recall,\n",
        "            **vit_metrics,\n",
        "            'missing_nouns': ', '.join(vit_missing)\n",
        "        })\n",
        "\n",
        "        if (idx + 1) % 20 == 0:\n",
        "            print(f\"Processed {idx + 1} images\")\n",
        "\n",
        "    # Compiling and saving all evaluation results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(output_csv, index=False)\n",
        "\n",
        "    # Computing and displaying model-wise average metrics\n",
        "    numeric_cols = results_df.select_dtypes(include=['number']).columns\n",
        "    avg_results = results_df.groupby('model')[numeric_cols].mean()\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    print(avg_results.to_markdown(floatfmt=\".2f\"))\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Executing the complete evaluation pipeline\n",
        "results = process_caption_comparison(\n",
        "    input_csv='mscoco-blip-vit_captions.csv',\n",
        "    output_csv='mscoco-blip-vit-metrics.csv'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAsNnjVCgaDD",
        "outputId": "73154ae9-4ff3-48ac-a838-9999d9a1206f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20 images\n",
            "Processed 40 images\n",
            "Processed 60 images\n",
            "Processed 80 images\n",
            "Processed 100 images\n",
            "Processed 120 images\n",
            "Processed 140 images\n",
            "Processed 160 images\n",
            "Processed 180 images\n",
            "Processed 200 images\n",
            "\n",
            "Average Metrics:\n",
            "| model   |   noun_recall |   color |   number |   text |   position |   shape |\n",
            "|:--------|--------------:|--------:|---------:|-------:|-----------:|--------:|\n",
            "| BLIP    |          0.35 |   -0.89 |     0.54 |  -1.00 |      -0.94 |   -0.99 |\n",
            "| ViT     |          0.42 |   -0.89 |     0.76 |  -1.00 |      -0.94 |   -0.99 |\n"
          ]
        }
      ]
    }
  ]
}
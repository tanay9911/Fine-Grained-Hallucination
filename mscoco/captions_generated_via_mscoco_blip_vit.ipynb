{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# To Install the required libraries\n",
        "!pip install transformers torch Pillow panda"
      ],
      "metadata": {
        "id": "jxz3b9fbaT72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-02STXA1YSp-"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from transformers import ViTImageProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
        "\n",
        "# Setting the paths\n",
        "IMG_DIR = '/content/drive/MyDrive/MSCOCO/train2014'\n",
        "CAPTIONS_PATH = '/content/drive/MyDrive/MSCOCO/annotations_trainval2014/annotations/captions_train2014.json'\n",
        "\n",
        "# Loading MSCOCO annotations\n",
        "with open(CAPTIONS_PATH, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Creating image_id to captions mapping\n",
        "image_id_to_captions = {}\n",
        "for annotation in coco_data['annotations']:\n",
        "    image_id = annotation['image_id']\n",
        "    caption = annotation['caption']\n",
        "    if image_id not in image_id_to_captions:\n",
        "        image_id_to_captions[image_id] = []\n",
        "    image_id_to_captions[image_id].append(caption)\n",
        "\n",
        "# Creating image_id to filename mapping AND build list of actually available files\n",
        "available_files = set(os.listdir(IMG_DIR))\n",
        "image_id_to_filename = {}\n",
        "valid_image_ids = []\n",
        "\n",
        "for image in coco_data['images']:\n",
        "    if image['file_name'] in available_files:\n",
        "        image_id_to_filename[image['id']] = image['file_name']\n",
        "        valid_image_ids.append(image['id'])\n",
        "\n",
        "print(f\"Found {len(valid_image_ids)} available images out of {len(coco_data['images'])}\")\n",
        "\n",
        "# Randomly sampling 200 image IDs from only the available ones\n",
        "random.seed(42)\n",
        "sampled_image_ids = random.sample(valid_image_ids, min(200, len(valid_image_ids)))\n",
        "\n",
        "# Initializing models\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# BLIP model\n",
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "# ViT-GPT2 model\n",
        "vit_processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "vit_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").to(device)\n",
        "vit_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "def generate_blip_caption(image_path):\n",
        "    try:\n",
        "        raw_image = Image.open(image_path).convert('RGB')\n",
        "        inputs = blip_processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "        out = blip_model.generate(**inputs)\n",
        "        caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    except Exception as e:\n",
        "        print(f\"BLIP Error processing {image_path}: {str(e)}\")\n",
        "        return \"BLIP caption generation failed\"\n",
        "\n",
        "def generate_vit_caption(image_path):\n",
        "    try:\n",
        "        raw_image = Image.open(image_path).convert('RGB')\n",
        "        pixel_values = vit_processor(images=raw_image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "        output_ids = vit_model.generate(pixel_values, max_length=50)\n",
        "        caption = vit_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    except Exception as e:\n",
        "        print(f\"ViT Error processing {image_path}: {str(e)}\")\n",
        "        return \"ViT caption generation failed\"\n",
        "\n",
        "# Processing the sampled images\n",
        "results = []\n",
        "for i, image_id in enumerate(sampled_image_ids):\n",
        "    filename = image_id_to_filename[image_id]\n",
        "    image_path = os.path.join(IMG_DIR, filename)\n",
        "\n",
        "    # Getting the MSCOCO captions (take first one)\n",
        "    coco_caption = image_id_to_captions[image_id][0]\n",
        "\n",
        "    # Generating BLIP caption\n",
        "    blip_caption = generate_blip_caption(image_path)\n",
        "\n",
        "    # Generating the ViT-GPT2 caption\n",
        "    vit_caption = generate_vit_caption(image_path)\n",
        "\n",
        "    results.append({\n",
        "        'image_name': filename,\n",
        "        'mscoco_caption': coco_caption,\n",
        "        'blip_caption': blip_caption,\n",
        "        'vit_caption': vit_caption\n",
        "    })\n",
        "\n",
        "    print(f\"Processed {i+1}/{len(sampled_image_ids)}: {filename}\")\n",
        "    print(f\"COCO: {coco_caption}\")\n",
        "    print(f\"BLIP: {blip_caption}\")\n",
        "    print(f\"ViT: {vit_caption}\")\n",
        "    print(\"---\")\n",
        "\n",
        "# Creating DataFrame and saving to CSV\n",
        "df = pd.DataFrame(results)\n",
        "output_path = 'mscoco-blip-vit_captions.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Done! CSV saved to {output_path}\")"
      ]
    }
  ]
}
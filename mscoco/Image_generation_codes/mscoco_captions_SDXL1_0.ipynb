{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7IYcK7K4MUp"
      },
      "outputs": [],
      "source": [
        "!pip install -U diffusers\n",
        "!pip install huggingface_hub\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "ftMr79-7448l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "\n",
        "# 1. Configuring the environment and defining paths\n",
        "\n",
        "csv_path = \"mscoco-blip-vit_captions.csv\"   # <-- your captions file\n",
        "model_name = \"SDXL\"\n",
        "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "save_dir = model_name\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# 2. Loading the Stable Diffusion XL model\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "# memory-saving modes\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_vae_slicing()\n",
        "pipe.enable_sequential_cpu_offload()\n",
        "\n",
        "\n",
        "# 3. Reading CSV in Chunks (skip first 'skip_rows' rows)\n",
        "\n",
        "chunksize = 50   # how many rows to process at once\n",
        "skip_rows = 0   # number of rows you want to skip this was done to avoid session crash because of all ram usage\n",
        "\n",
        "print(f\"Reading {csv_path} in chunks of {chunksize} rows, skipping first {skip_rows} rows...\")\n",
        "\n",
        "reader = pd.read_csv(csv_path, chunksize=chunksize, skiprows=range(1, skip_rows+1))\n",
        "# NOTE: range(1, N+1) skips the first N rows but keeps the header\n",
        "\n",
        "for chunk in reader:\n",
        "    for row in tqdm(chunk.itertuples(), total=len(chunk), desc=f\"Generating with {model_name}\"):\n",
        "        image_name = row.image_name\n",
        "        caption = row.mscoco_caption   # <-- caption text\n",
        "\n",
        "\n",
        "        # 4. Generating Image\n",
        "\n",
        "        image = pipe(caption, height=512, width=512).images[0]\n",
        "\n",
        "\n",
        "        # 5. Saving Image\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name}-{image_name}.jpeg\")\n",
        "        image.save(save_path, \"JPEG\")\n",
        "\n",
        "\n",
        "        # 6. Freeing the Memory\n",
        "\n",
        "        del image\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\" All images generated and saved!\")\n",
        "import shutil # downloading the folder\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(\"SDXL\", 'zip', \"SDXL\")\n",
        "\n",
        "# Download to your local machine\n",
        "from google.colab import files\n",
        "files.download(\"SDXL.zip\")\n"
      ],
      "metadata": {
        "id": "43Av6kkC43vI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
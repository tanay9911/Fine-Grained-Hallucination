{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQtFQlyVxShY"
      },
      "outputs": [],
      "source": [
        "!pip install -U diffusers\n",
        "!pip install huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlUQRSaHx8lw"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6EgYZuSx9Dn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "# 1. Configuring the environment and defining paths\n",
        "\n",
        "csv_path = \"mscoco-blip-vit_captions.csv\"   # Specifying the path of the captions CSV file\n",
        "model_name = \"SD2\"  # Assigning a name to the model for saving outputs\n",
        "model_id = \"stabilityai/stable-diffusion-2-base\"  # Specifying the Stable Diffusion 2 model identifier\n",
        "save_dir = model_name  # Setting the output directory to match the model name\n",
        "os.makedirs(save_dir, exist_ok=True)  # Creating the output directory if it is not already existing\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Detecting and assigning GPU or CPU device\n",
        "\n",
        "\n",
        "# 2. Loading the Stable Diffusion 2 model\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16\n",
        ").to(device)  # Loading the SD2 model with half precision on the selected device\n",
        "\n",
        "# Enabling memory optimization techniques\n",
        "pipe.enable_attention_slicing()  # Enabling attention slicing to reduce memory usage\n",
        "pipe.enable_sequential_cpu_offload()  # Enabling sequential offloading of model parts to CPU when not in use\n",
        "\n",
        "\n",
        "# 3. Reading the CSV file in chunks while skipping specified rows\n",
        "\n",
        "chunksize = 50   # Defining how many rows are being processed per chunk\n",
        "skip_rows = 0   # Defining how many rows are being skipped at the start of the file\n",
        "\n",
        "print(f\"Reading {csv_path} in chunks of {chunksize} rows, skipping first {skip_rows} rows...\")\n",
        "\n",
        "reader = pd.read_csv(csv_path, chunksize=chunksize, skiprows=range(1, skip_rows+1))\n",
        "# Using range(1, N+1) for ensuring the first N rows are being skipped while keeping the header row intact\n",
        "\n",
        "for chunk in reader:\n",
        "    for row in tqdm(chunk.itertuples(), total=len(chunk), desc=f\"Generating with {model_name}\"):\n",
        "        image_name = row.image_name\n",
        "        caption = row.mscoco_caption   # Extracting the caption text for image generation\n",
        "\n",
        "\n",
        "        # 4. Generating an image from the caption\n",
        "\n",
        "        image = pipe(caption, height=512, width=512).images[0]\n",
        "\n",
        "\n",
        "        # 5. Saving the generated image\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name}-{image_name}.jpeg\")\n",
        "        image.save(save_path, \"JPEG\")\n",
        "\n",
        "\n",
        "        # 6. Releasing memory resources\n",
        "\n",
        "        del image  # Deleting the image object from memory\n",
        "        torch.cuda.empty_cache()  # Clearing unused GPU memory\n",
        "        gc.collect()  # Running garbage collection to free additional memory\n",
        "\n",
        "print(\" All images are being generated and saved successfully!\")\n",
        "\n",
        "import shutil  # Importing library for handling file operations\n",
        "\n",
        "# Creating a zip archive of the output folder\n",
        "shutil.make_archive(\"SD2\", 'zip', \"SD2\")\n",
        "\n",
        "# Downloading the zipped folder to the local machine\n",
        "from google.colab import files\n",
        "files.download(\"SD2.zip\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

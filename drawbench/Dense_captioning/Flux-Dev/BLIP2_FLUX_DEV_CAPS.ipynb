{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#This code takes the segments generated by Grounding dino + SAM (Flux-Dev_images_segments) and passes them to BLIP to get dense captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofuXNswDEOxf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes torch pillow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Load BLIP2 Instruct Model in 8-bit ===\n",
        "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "blip_processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
        "blip_model = InstructBlipForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/instructblip-vicuna-7b\",\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS00SkDvM8JW",
        "outputId": "9d885d6b-9a96-4855-de88-7e4bba87eb07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "# === Paths ===\n",
        "base_path = \"/content/drive/MyDrive/Flux-Dev_images_segments\"\n",
        "output_json = \"/content/drive/MyDrive/BLIP2_FLUX-DEV_CAPS.json\"\n",
        "\n",
        "# === Prompt ===\n",
        "prompt = (\n",
        "    \"Describe the image with a focus on the intricate details of the object, \"\n",
        "    \"including their color, shape, and number. Include any physical aspects that \"\n",
        "    \"appear unusual or incorrect according to general knowledge.\"\n",
        ")\n",
        "\n",
        "# === Function to caption one image (uses existing blip_model + blip_processor) ===\n",
        "def get_blip2_caption(img_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs = blip_processor(img, prompt, return_tensors=\"pt\").to(blip_model.device)\n",
        "    out = blip_model.generate(**inputs, max_length=100, do_sample=False)\n",
        "    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    # ðŸ”¹ Strip prompt echo if it appears at the start\n",
        "    if caption.startswith(prompt):\n",
        "        caption = caption[len(prompt):].strip()\n",
        "\n",
        "    return caption\n",
        "\n",
        "# === Load existing captions if JSON already exists ===\n",
        "if os.path.exists(output_json):\n",
        "    with open(output_json, \"r\") as f:\n",
        "        all_captions = json.load(f)\n",
        "    print(f\" Resuming from {output_json}\")\n",
        "else:\n",
        "    all_captions = {}\n",
        "\n",
        "# === Main Loop ===\n",
        "folders = sorted(os.listdir(base_path))\n",
        "for folder_name in folders:\n",
        "    if folder_name in all_captions:  # skip already processed\n",
        "        print(f\"Skipping folder {folder_name} (already done)\")\n",
        "        continue\n",
        "\n",
        "    folder_path = os.path.join(base_path, folder_name)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n Processing folder {folder_name} ...\")\n",
        "    segment_captions = {}\n",
        "\n",
        "    seg_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    for seg_file in seg_files:\n",
        "        seg_path = os.path.join(folder_path, seg_file)\n",
        "        print(f\"    Segment: {seg_file}\")\n",
        "        try:\n",
        "            caption = get_blip2_caption(seg_path)\n",
        "        except Exception as e:\n",
        "            caption = f\"ERROR: {e}\"\n",
        "        print(f\"      Caption: {caption}\")\n",
        "        segment_captions[seg_file] = caption\n",
        "\n",
        "    if segment_captions:\n",
        "        all_captions[folder_name] = segment_captions\n",
        "\n",
        "        # Save after each folder\n",
        "        with open(output_json, \"w\") as f:\n",
        "            json.dump(all_captions, f, indent=2)\n",
        "\n",
        "        print(f\" Saved progress for folder {folder_name}\")\n",
        "\n",
        "print(f\"\\n All captions saved to {output_json}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

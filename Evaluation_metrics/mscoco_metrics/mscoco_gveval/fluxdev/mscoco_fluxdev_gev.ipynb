{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_fQvk3IXMW5"
      },
      "outputs": [],
      "source": [
        "!pip install openai pandas aiohttp tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Setup ---\n",
        "import os\n",
        "import base64\n",
        "import json\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from openai import AsyncOpenAI\n",
        "import time\n",
        "import nest_asyncio\n",
        "\n",
        "# Patch asyncio for Jupyter/Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# GitHub token\n",
        "os.environ[\"GITHUB_TOKEN\"] = \"\"\n",
        "\n",
        "# Instantiate client with GitHub endpoint\n",
        "client = AsyncOpenAI(\n",
        "    base_url=\"https://models.github.ai/inference\",\n",
        "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
        ")\n",
        "\n",
        "MODEL = \"openai/gpt-4o-mini\"\n",
        "\n",
        "# Rate limits\n",
        "RPM = 15        # requests per minute\n",
        "RPD = 150       # requests per day\n",
        "CONCURRENT = 5  # max concurrent requests\n",
        "\n",
        "# --- Step 4: Utils & G-VEval style prompt ---\n",
        "def encode_image(image_path: Path):\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "async def gveval_score_async(prompt_text: str, image_path: Path, meta_caption: str):\n",
        "    image_b64 = encode_image(image_path)\n",
        "\n",
        "    system_prompt = \"\"\"You are a caption evaluation module following G-VEval from AAAI 2025.\n",
        "You will be given:\n",
        "- A reference caption.\n",
        "- A candidate caption (meta-caption) generated from the image.\n",
        "- The image itself.\n",
        "\n",
        "You must produce:\n",
        "- Four scores (Accuracy, Completeness, Conciseness, Relevance), each from 0 to 100.\n",
        "- An overall score from 0 to 100.\n",
        "- A short reasoning explaining the main strengths & weaknesses.\n",
        "\n",
        "Return strictly JSON, exactly this structure:\n",
        "\n",
        "{\n",
        "  \"accuracy\": <int 0-100>,\n",
        "  \"completeness\": <int 0-100>,\n",
        "  \"conciseness\": <int 0-100>,\n",
        "  \"relevance\": <int 0-100>,\n",
        "  \"overall\": <int 0-100>,\n",
        "  \"reason\": \"<short explanation>\"\n",
        "}\"\"\"\n",
        "\n",
        "    user_prompt = f\"Reference: {prompt_text}\\nCandidate: {meta_caption}\"\n",
        "\n",
        "    resp = await client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": user_prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "    )\n",
        "\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def safe_append_jsonl(out_path: str, record: dict):\n",
        "    \"\"\"Append record to jsonl safely (flush/sync) without overwriting previous content.\"\"\"\n",
        "    with open(out_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "        f.flush()\n",
        "        os.fsync(f.fileno())\n",
        "\n",
        "async def process_triple(triple, out_path: str):\n",
        "    img_name, prompt, meta_caption, img_path = triple\n",
        "    try:\n",
        "        json_result = await gveval_score_async(prompt, img_path, meta_caption)\n",
        "        record = {\n",
        "            \"image_name\": img_name,\n",
        "            \"result\": json.loads(json_result) if isinstance(json_result, str) else json_result\n",
        "        }\n",
        "        safe_append_jsonl(out_path, record)\n",
        "        print(f\"Saved: {img_name}\")\n",
        "        return record\n",
        "    except Exception as e:\n",
        "        print(f\"Error for {img_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "async def run_eval(triples, out_path: str):\n",
        "    sem = asyncio.Semaphore(CONCURRENT)\n",
        "    start_time = time.time()\n",
        "    completed = 0\n",
        "    results = []\n",
        "\n",
        "    total = len(triples)\n",
        "    for i, triple in enumerate(triples, start=1):\n",
        "        async with sem:\n",
        "            # enforce per-minute limit\n",
        "            elapsed = time.time() - start_time\n",
        "            if completed >= RPM and elapsed < 60:\n",
        "                await asyncio.sleep(60 - elapsed)\n",
        "                completed = 0\n",
        "                start_time = time.time()\n",
        "            completed += 1\n",
        "            rec = await process_triple(triple, out_path)\n",
        "            if rec:\n",
        "                results.append(rec)\n",
        "            # verbose progress\n",
        "            print(f\"[{i}/{total}] Processed image: {triple[0]} | Total saved: {len(results)}\")\n",
        "            if len(results) >= RPD:\n",
        "                print(\"Hit daily cap, stopping for today.\")\n",
        "                break\n",
        "    return results\n",
        "\n",
        "# --- Step 5: Load triples ---\n",
        "def load_triples(prompt_csv: str, meta_csv: str, image_folder: str):\n",
        "    df_prompts = pd.read_csv(prompt_csv)\n",
        "    df_meta = pd.read_csv(meta_csv)\n",
        "\n",
        "    # strip spaces from headers just in case\n",
        "    df_prompts.columns = df_prompts.columns.str.strip()\n",
        "    df_meta.columns = df_meta.columns.str.strip()\n",
        "\n",
        "    triples = []\n",
        "    for _, row in df_meta.iterrows():\n",
        "        img_name = str(row[\"image_name\"]).strip()\n",
        "        meta_caption = row.get(\"Meta Caption\", \"\")\n",
        "\n",
        "        if not isinstance(meta_caption, str) or meta_caption.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        # find reference caption from df_prompts (matching image_name)\n",
        "        prompt_match = df_prompts.loc[df_prompts[\"image_name\"] == img_name, \"mscoco_caption\"].values\n",
        "        prompt = prompt_match[0] if len(prompt_match) > 0 else \"\"\n",
        "\n",
        "        # find image file\n",
        "        img_path = None\n",
        "        for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "            candidate = Path(image_folder) / f\"{img_name}{ext}\"\n",
        "            if candidate.exists():\n",
        "                img_path = candidate\n",
        "                break\n",
        "        if img_path is None:\n",
        "            continue\n",
        "\n",
        "        triples.append((img_name, prompt, meta_caption, img_path))\n",
        "\n",
        "    return triples\n",
        "\n",
        "# --- Step 6: Run for SDXL model ---\n",
        "base = \"/content/drive/MyDrive/gveval\"\n",
        "prompt_csv = f\"{base}/mscoco_captions.csv\"\n",
        "meta_csv = f\"{base}/fluxdev_meta.csv\"\n",
        "image_folder = f\"{base}/fluxdev\"\n",
        "out_file = f\"{base}/mscoco_fluxdev_gveval.jsonl\"\n",
        "\n",
        "# Prepare data\n",
        "triples = load_triples(prompt_csv, meta_csv, image_folder)\n",
        "print(f\"Loaded {len(triples)} triples.\")\n",
        "\n",
        "# Load already processed IDs and **filter triples before sending to GPT**\n",
        "done_ids = set()\n",
        "if Path(out_file).exists():\n",
        "    with open(out_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                rec = json.loads(line)\n",
        "                done_ids.add(rec[\"image_name\"])\n",
        "            except:\n",
        "                pass\n",
        "print(f\"Already done: {len(done_ids)}\")\n",
        "\n",
        "# Filter out already processed triples\n",
        "triples_to_process = [t for t in triples if t[0] not in done_ids]\n",
        "print(f\"Remaining images to process: {len(triples_to_process)}\")\n",
        "\n",
        "# Run evaluation (Colab-safe)\n",
        "loop = asyncio.get_event_loop()\n",
        "results = loop.run_until_complete(run_eval(triples_to_process, out_file))\n",
        "print(\"Evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kVzlqtdXT_h",
        "outputId": "ffe03b98-51a4-4942-f888-8684b0a0c706"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 triples.\n",
            "Already done: 119\n",
            "Remaining images to process: 81\n",
            "Saved: COCO_train2014_000000330575\n",
            "[1/81] Processed image: COCO_train2014_000000330575 | Total saved: 1\n",
            "Saved: COCO_train2014_000000335717\n",
            "[2/81] Processed image: COCO_train2014_000000335717 | Total saved: 2\n",
            "Saved: COCO_train2014_000000336003\n",
            "[3/81] Processed image: COCO_train2014_000000336003 | Total saved: 3\n",
            "Saved: COCO_train2014_000000337585\n",
            "[4/81] Processed image: COCO_train2014_000000337585 | Total saved: 4\n",
            "Saved: COCO_train2014_000000339130\n",
            "[5/81] Processed image: COCO_train2014_000000339130 | Total saved: 5\n",
            "Saved: COCO_train2014_000000346726\n",
            "[6/81] Processed image: COCO_train2014_000000346726 | Total saved: 6\n",
            "Error for COCO_train2014_000000351298: Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n",
            "[7/81] Processed image: COCO_train2014_000000351298 | Total saved: 6\n",
            "Saved: COCO_train2014_000000351451\n",
            "[8/81] Processed image: COCO_train2014_000000351451 | Total saved: 7\n",
            "Saved: COCO_train2014_000000364416\n",
            "[9/81] Processed image: COCO_train2014_000000364416 | Total saved: 8\n",
            "Saved: COCO_train2014_000000364522\n",
            "[10/81] Processed image: COCO_train2014_000000364522 | Total saved: 9\n",
            "Saved: COCO_train2014_000000365452\n",
            "[11/81] Processed image: COCO_train2014_000000365452 | Total saved: 10\n",
            "Saved: COCO_train2014_000000365592\n",
            "[12/81] Processed image: COCO_train2014_000000365592 | Total saved: 11\n",
            "Saved: COCO_train2014_000000366713\n",
            "[13/81] Processed image: COCO_train2014_000000366713 | Total saved: 12\n",
            "Saved: COCO_train2014_000000370543\n",
            "[14/81] Processed image: COCO_train2014_000000370543 | Total saved: 13\n",
            "Saved: COCO_train2014_000000371412\n",
            "[15/81] Processed image: COCO_train2014_000000371412 | Total saved: 14\n",
            "Saved: COCO_train2014_000000378618\n",
            "[16/81] Processed image: COCO_train2014_000000378618 | Total saved: 15\n",
            "Saved: COCO_train2014_000000380717\n",
            "[17/81] Processed image: COCO_train2014_000000380717 | Total saved: 16\n",
            "Saved: COCO_train2014_000000382142\n",
            "[18/81] Processed image: COCO_train2014_000000382142 | Total saved: 17\n",
            "Saved: COCO_train2014_000000382441\n",
            "[19/81] Processed image: COCO_train2014_000000382441 | Total saved: 18\n",
            "Saved: COCO_train2014_000000386085\n",
            "[20/81] Processed image: COCO_train2014_000000386085 | Total saved: 19\n",
            "Saved: COCO_train2014_000000388353\n",
            "[21/81] Processed image: COCO_train2014_000000388353 | Total saved: 20\n",
            "Saved: COCO_train2014_000000393046\n",
            "[22/81] Processed image: COCO_train2014_000000393046 | Total saved: 21\n",
            "Saved: COCO_train2014_000000396296\n",
            "[23/81] Processed image: COCO_train2014_000000396296 | Total saved: 22\n",
            "Saved: COCO_train2014_000000399399\n",
            "[24/81] Processed image: COCO_train2014_000000399399 | Total saved: 23\n",
            "Saved: COCO_train2014_000000400245\n",
            "[25/81] Processed image: COCO_train2014_000000400245 | Total saved: 24\n",
            "Saved: COCO_train2014_000000401299\n",
            "[26/81] Processed image: COCO_train2014_000000401299 | Total saved: 25\n",
            "Saved: COCO_train2014_000000402243\n",
            "[27/81] Processed image: COCO_train2014_000000402243 | Total saved: 26\n",
            "Saved: COCO_train2014_000000402908\n",
            "[28/81] Processed image: COCO_train2014_000000402908 | Total saved: 27\n",
            "Saved: COCO_train2014_000000407318\n",
            "[29/81] Processed image: COCO_train2014_000000407318 | Total saved: 28\n",
            "Saved: COCO_train2014_000000407349\n",
            "[30/81] Processed image: COCO_train2014_000000407349 | Total saved: 29\n",
            "Saved: COCO_train2014_000000407806\n",
            "[31/81] Processed image: COCO_train2014_000000407806 | Total saved: 30\n",
            "Saved: COCO_train2014_000000413754\n",
            "[32/81] Processed image: COCO_train2014_000000413754 | Total saved: 31\n",
            "Saved: COCO_train2014_000000415458\n",
            "[33/81] Processed image: COCO_train2014_000000415458 | Total saved: 32\n",
            "Saved: COCO_train2014_000000422305\n",
            "[34/81] Processed image: COCO_train2014_000000422305 | Total saved: 33\n",
            "Saved: COCO_train2014_000000423734\n",
            "[35/81] Processed image: COCO_train2014_000000423734 | Total saved: 34\n",
            "Saved: COCO_train2014_000000428602\n",
            "[36/81] Processed image: COCO_train2014_000000428602 | Total saved: 35\n",
            "Saved: COCO_train2014_000000434549\n",
            "[37/81] Processed image: COCO_train2014_000000434549 | Total saved: 36\n",
            "Saved: COCO_train2014_000000435322\n",
            "[38/81] Processed image: COCO_train2014_000000435322 | Total saved: 37\n",
            "Saved: COCO_train2014_000000452014\n",
            "[39/81] Processed image: COCO_train2014_000000452014 | Total saved: 38\n",
            "Saved: COCO_train2014_000000452968\n",
            "[40/81] Processed image: COCO_train2014_000000452968 | Total saved: 39\n",
            "Saved: COCO_train2014_000000458785\n",
            "[41/81] Processed image: COCO_train2014_000000458785 | Total saved: 40\n",
            "Saved: COCO_train2014_000000459401\n",
            "[42/81] Processed image: COCO_train2014_000000459401 | Total saved: 41\n",
            "Saved: COCO_train2014_000000462767\n",
            "[43/81] Processed image: COCO_train2014_000000462767 | Total saved: 42\n",
            "Saved: COCO_train2014_000000465247\n",
            "[44/81] Processed image: COCO_train2014_000000465247 | Total saved: 43\n",
            "Saved: COCO_train2014_000000467223\n",
            "[45/81] Processed image: COCO_train2014_000000467223 | Total saved: 44\n",
            "Saved: COCO_train2014_000000470970\n",
            "[46/81] Processed image: COCO_train2014_000000470970 | Total saved: 45\n",
            "Saved: COCO_train2014_000000471755\n",
            "[47/81] Processed image: COCO_train2014_000000471755 | Total saved: 46\n",
            "Saved: COCO_train2014_000000472913\n",
            "[48/81] Processed image: COCO_train2014_000000472913 | Total saved: 47\n",
            "Saved: COCO_train2014_000000481688\n",
            "[49/81] Processed image: COCO_train2014_000000481688 | Total saved: 48\n",
            "Saved: COCO_train2014_000000483794\n",
            "[50/81] Processed image: COCO_train2014_000000483794 | Total saved: 49\n",
            "Saved: COCO_train2014_000000488390\n",
            "[51/81] Processed image: COCO_train2014_000000488390 | Total saved: 50\n",
            "Saved: COCO_train2014_000000491117\n",
            "[52/81] Processed image: COCO_train2014_000000491117 | Total saved: 51\n",
            "Saved: COCO_train2014_000000497402\n",
            "[53/81] Processed image: COCO_train2014_000000497402 | Total saved: 52\n",
            "Saved: COCO_train2014_000000503985\n",
            "[54/81] Processed image: COCO_train2014_000000503985 | Total saved: 53\n",
            "Saved: COCO_train2014_000000505086\n",
            "[55/81] Processed image: COCO_train2014_000000505086 | Total saved: 54\n",
            "Saved: COCO_train2014_000000510914\n",
            "[56/81] Processed image: COCO_train2014_000000510914 | Total saved: 55\n",
            "Saved: COCO_train2014_000000517321\n",
            "[57/81] Processed image: COCO_train2014_000000517321 | Total saved: 56\n",
            "Saved: COCO_train2014_000000519076\n",
            "[58/81] Processed image: COCO_train2014_000000519076 | Total saved: 57\n",
            "Saved: COCO_train2014_000000523766\n",
            "[59/81] Processed image: COCO_train2014_000000523766 | Total saved: 58\n",
            "Saved: COCO_train2014_000000524180\n",
            "[60/81] Processed image: COCO_train2014_000000524180 | Total saved: 59\n",
            "Saved: COCO_train2014_000000526232\n",
            "[61/81] Processed image: COCO_train2014_000000526232 | Total saved: 60\n",
            "Saved: COCO_train2014_000000526696\n",
            "[62/81] Processed image: COCO_train2014_000000526696 | Total saved: 61\n",
            "Saved: COCO_train2014_000000527557\n",
            "[63/81] Processed image: COCO_train2014_000000527557 | Total saved: 62\n",
            "Saved: COCO_train2014_000000527858\n",
            "[64/81] Processed image: COCO_train2014_000000527858 | Total saved: 63\n",
            "Saved: COCO_train2014_000000529545\n",
            "[65/81] Processed image: COCO_train2014_000000529545 | Total saved: 64\n",
            "Saved: COCO_train2014_000000531948\n",
            "[66/81] Processed image: COCO_train2014_000000531948 | Total saved: 65\n",
            "Saved: COCO_train2014_000000532461\n",
            "[67/81] Processed image: COCO_train2014_000000532461 | Total saved: 66\n",
            "Saved: COCO_train2014_000000534702\n",
            "[68/81] Processed image: COCO_train2014_000000534702 | Total saved: 67\n",
            "Saved: COCO_train2014_000000538776\n",
            "[69/81] Processed image: COCO_train2014_000000538776 | Total saved: 68\n",
            "Saved: COCO_train2014_000000542033\n",
            "[70/81] Processed image: COCO_train2014_000000542033 | Total saved: 69\n",
            "Saved: COCO_train2014_000000542674\n",
            "[71/81] Processed image: COCO_train2014_000000542674 | Total saved: 70\n",
            "Saved: COCO_train2014_000000546300\n",
            "[72/81] Processed image: COCO_train2014_000000546300 | Total saved: 71\n",
            "Saved: COCO_train2014_000000552093\n",
            "[73/81] Processed image: COCO_train2014_000000552093 | Total saved: 72\n",
            "Saved: COCO_train2014_000000552962\n",
            "[74/81] Processed image: COCO_train2014_000000552962 | Total saved: 73\n",
            "Saved: COCO_train2014_000000555183\n",
            "[75/81] Processed image: COCO_train2014_000000555183 | Total saved: 74\n",
            "Saved: COCO_train2014_000000556481\n",
            "[76/81] Processed image: COCO_train2014_000000556481 | Total saved: 75\n",
            "Saved: COCO_train2014_000000556838\n",
            "[77/81] Processed image: COCO_train2014_000000556838 | Total saved: 76\n",
            "Saved: COCO_train2014_000000565600\n",
            "[78/81] Processed image: COCO_train2014_000000565600 | Total saved: 77\n",
            "Saved: COCO_train2014_000000569203\n",
            "[79/81] Processed image: COCO_train2014_000000569203 | Total saved: 78\n",
            "Saved: COCO_train2014_000000570569\n",
            "[80/81] Processed image: COCO_train2014_000000570569 | Total saved: 79\n",
            "Saved: COCO_train2014_000000578580\n",
            "[81/81] Processed image: COCO_train2014_000000578580 | Total saved: 80\n",
            "Evaluation completed.\n"
          ]
        }
      ]
    }
  ]
}
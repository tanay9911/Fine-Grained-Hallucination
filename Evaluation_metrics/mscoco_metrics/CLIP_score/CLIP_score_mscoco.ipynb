{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch torchvision ftfy regex tqdm"
      ],
      "metadata": {
        "id": "sHcoo70SLsgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m3FTpgDLhYt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# ===== 1. Mount Google Drive =====\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ===== 2. Paths =====\n",
        "image_root_folder = \"/content/drive/MyDrive/TTI_Models_images\"  # Folder containing Flux-Dev, SD2, SDXL\n",
        "baseline_file = \"/content/drive/MyDrive/mscoco_captions.csv\"     # MSCOCO captions CSV\n",
        "\n",
        "# ===== 3. Load MSCOCO captions =====\n",
        "baseline_df = pd.read_csv(baseline_file)\n",
        "baseline_df = baseline_df[[\"image_name\", \"mscoco_caption\"]]\n",
        "\n",
        "# ===== 4. Load CLIP model =====\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# ===== 5. Compute average CLIPScore per model =====\n",
        "model_folders = [\"Flux-Dev\", \"SD2\", \"SDXL\"]\n",
        "average_clip_scores = {}\n",
        "\n",
        "for model_name in model_folders:\n",
        "    print(f\"\\nProcessing model: {model_name}\")\n",
        "    folder_path = os.path.join(image_root_folder, model_name)\n",
        "    model_scores = []\n",
        "\n",
        "    for _, row in tqdm(baseline_df.iterrows(), total=len(baseline_df)):\n",
        "        image_name = row[\"image_name\"]\n",
        "        caption = str(row[\"mscoco_caption\"]).strip()\n",
        "\n",
        "        # Look for image inside the current model folder\n",
        "        possible_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "        image_path = None\n",
        "        for ext in possible_extensions:\n",
        "            candidate_path = os.path.join(folder_path, f\"{image_name}{ext}\")\n",
        "            if os.path.exists(candidate_path):\n",
        "                image_path = candidate_path\n",
        "                break\n",
        "\n",
        "        if image_path is None or caption == \"\":\n",
        "            continue  # skip missing images or empty captions\n",
        "\n",
        "        # Compute CLIPScore\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        inputs = processor(text=[caption], images=[image], return_tensors=\"pt\", padding=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = clip_model(**inputs)\n",
        "            image_embeds = outputs.image_embeds\n",
        "            text_embeds = outputs.text_embeds\n",
        "            sim = torch.nn.functional.cosine_similarity(image_embeds, text_embeds)\n",
        "            model_scores.append(sim.item())\n",
        "\n",
        "    # Average score for this model\n",
        "    avg_score = sum(model_scores) / len(model_scores) if model_scores else 0.0\n",
        "    average_clip_scores[model_name] = avg_score\n",
        "    print(f\"{model_name} â†’ Average CLIPScore: {avg_score:.4f}\")\n",
        "\n",
        "# ===== 6. Save average scores =====\n",
        "out_json = os.path.join(image_root_folder, \"mscoco_clip_avg_scores.json\")\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(average_clip_scores, f, indent=4)\n",
        "\n",
        "print(f\"\\n Average CLIP scores saved to: {out_json}\")\n",
        "print(average_clip_scores)\n"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pandas aiohttp tqdm"
      ],
      "metadata": {
        "id": "L-EG2QQSE0AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADwXxcvUDlzq",
        "outputId": "16964c9d-c856-46da-f193-e2d662efb418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 triples.\n",
            "Already done: 150\n",
            "Remaining images to process: 50\n",
            "Saved: 150\n",
            "[1/50] Processed image: 150 | Total saved: 1\n",
            "Saved: 151\n",
            "[2/50] Processed image: 151 | Total saved: 2\n",
            "Saved: 152\n",
            "[3/50] Processed image: 152 | Total saved: 3\n",
            "Saved: 153\n",
            "[4/50] Processed image: 153 | Total saved: 4\n",
            "Saved: 154\n",
            "[5/50] Processed image: 154 | Total saved: 5\n",
            "Saved: 155\n",
            "[6/50] Processed image: 155 | Total saved: 6\n",
            "Saved: 156\n",
            "[7/50] Processed image: 156 | Total saved: 7\n",
            "Saved: 157\n",
            "[8/50] Processed image: 157 | Total saved: 8\n",
            "Saved: 158\n",
            "[9/50] Processed image: 158 | Total saved: 9\n",
            "Saved: 159\n",
            "[10/50] Processed image: 159 | Total saved: 10\n",
            "Saved: 160\n",
            "[11/50] Processed image: 160 | Total saved: 11\n",
            "Saved: 161\n",
            "[12/50] Processed image: 161 | Total saved: 12\n",
            "Saved: 162\n",
            "[13/50] Processed image: 162 | Total saved: 13\n",
            "Saved: 163\n",
            "[14/50] Processed image: 163 | Total saved: 14\n",
            "Saved: 164\n",
            "[15/50] Processed image: 164 | Total saved: 15\n",
            "Saved: 165\n",
            "[16/50] Processed image: 165 | Total saved: 16\n",
            "Saved: 166\n",
            "[17/50] Processed image: 166 | Total saved: 17\n",
            "Saved: 167\n",
            "[18/50] Processed image: 167 | Total saved: 18\n",
            "Saved: 168\n",
            "[19/50] Processed image: 168 | Total saved: 19\n",
            "Saved: 169\n",
            "[20/50] Processed image: 169 | Total saved: 20\n",
            "Saved: 170\n",
            "[21/50] Processed image: 170 | Total saved: 21\n",
            "Saved: 171\n",
            "[22/50] Processed image: 171 | Total saved: 22\n",
            "Saved: 172\n",
            "[23/50] Processed image: 172 | Total saved: 23\n",
            "Saved: 173\n",
            "[24/50] Processed image: 173 | Total saved: 24\n",
            "Saved: 174\n",
            "[25/50] Processed image: 174 | Total saved: 25\n",
            "Saved: 175\n",
            "[26/50] Processed image: 175 | Total saved: 26\n",
            "Saved: 176\n",
            "[27/50] Processed image: 176 | Total saved: 27\n",
            "Saved: 177\n",
            "[28/50] Processed image: 177 | Total saved: 28\n",
            "Saved: 178\n",
            "[29/50] Processed image: 178 | Total saved: 29\n",
            "Saved: 179\n",
            "[30/50] Processed image: 179 | Total saved: 30\n",
            "Saved: 180\n",
            "[31/50] Processed image: 180 | Total saved: 31\n",
            "Saved: 181\n",
            "[32/50] Processed image: 181 | Total saved: 32\n",
            "Saved: 182\n",
            "[33/50] Processed image: 182 | Total saved: 33\n",
            "Saved: 183\n",
            "[34/50] Processed image: 183 | Total saved: 34\n",
            "Saved: 184\n",
            "[35/50] Processed image: 184 | Total saved: 35\n",
            "Saved: 185\n",
            "[36/50] Processed image: 185 | Total saved: 36\n",
            "Saved: 186\n",
            "[37/50] Processed image: 186 | Total saved: 37\n",
            "Saved: 187\n",
            "[38/50] Processed image: 187 | Total saved: 38\n",
            "Saved: 188\n",
            "[39/50] Processed image: 188 | Total saved: 39\n",
            "Saved: 189\n",
            "[40/50] Processed image: 189 | Total saved: 40\n",
            "Saved: 190\n",
            "[41/50] Processed image: 190 | Total saved: 41\n",
            "Saved: 191\n",
            "[42/50] Processed image: 191 | Total saved: 42\n",
            "Saved: 192\n",
            "[43/50] Processed image: 192 | Total saved: 43\n",
            "Saved: 193\n",
            "[44/50] Processed image: 193 | Total saved: 44\n",
            "Saved: 194\n",
            "[45/50] Processed image: 194 | Total saved: 45\n",
            "Saved: 195\n",
            "[46/50] Processed image: 195 | Total saved: 46\n",
            "Saved: 196\n",
            "[47/50] Processed image: 196 | Total saved: 47\n",
            "Saved: 197\n",
            "[48/50] Processed image: 197 | Total saved: 48\n",
            "Saved: 198\n",
            "[49/50] Processed image: 198 | Total saved: 49\n",
            "Saved: 199\n",
            "[50/50] Processed image: 199 | Total saved: 50\n",
            "Evaluation completed.\n"
          ]
        }
      ],
      "source": [
        "# --- Step 3: Setup ---\n",
        "import os\n",
        "import base64\n",
        "import json\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from openai import AsyncOpenAI\n",
        "import time\n",
        "import nest_asyncio\n",
        "\n",
        "# Patch asyncio for Jupyter/Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# GitHub token\n",
        "os.environ[\"GITHUB_TOKEN\"] = \"\"\n",
        "\n",
        "# Instantiate client with GitHub endpoint\n",
        "client = AsyncOpenAI(\n",
        "    base_url=\"https://models.github.ai/inference\",\n",
        "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
        ")\n",
        "\n",
        "MODEL = \"openai/gpt-4o-mini\"\n",
        "\n",
        "# Rate limits\n",
        "RPM = 15        # requests per minute\n",
        "RPD = 150       # requests per day\n",
        "CONCURRENT = 5  # max concurrent requests\n",
        "\n",
        "# --- Step 4: Utils & G-VEval style prompt ---\n",
        "def encode_image(image_path: Path):\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "async def gveval_score_async(prompt_text: str, image_path: Path, meta_caption: str):\n",
        "    image_b64 = encode_image(image_path)\n",
        "\n",
        "    system_prompt = \"\"\"You are a caption evaluation module following G-VEval from AAAI 2025.\n",
        "You will be given:\n",
        "- A reference caption.\n",
        "- A candidate caption (meta-caption) generated from the image.\n",
        "- The image itself.\n",
        "\n",
        "You must produce:\n",
        "- Four scores (Accuracy, Completeness, Conciseness, Relevance), each from 0 to 100.\n",
        "- An overall score from 0 to 100.\n",
        "- A short reasoning explaining the main strengths & weaknesses.\n",
        "\n",
        "Return strictly JSON, exactly this structure:\n",
        "\n",
        "{\n",
        "  \"accuracy\": <int 0-100>,\n",
        "  \"completeness\": <int 0-100>,\n",
        "  \"conciseness\": <int 0-100>,\n",
        "  \"relevance\": <int 0-100>,\n",
        "  \"overall\": <int 0-100>,\n",
        "  \"reason\": \"<short explanation>\"\n",
        "}\"\"\"\n",
        "\n",
        "    user_prompt = f\"Reference: {prompt_text}\\nCandidate: {meta_caption}\"\n",
        "\n",
        "    resp = await client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": user_prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "    )\n",
        "\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def safe_append_jsonl(out_path: str, record: dict):\n",
        "    \"\"\"Append record to jsonl safely (flush/sync) without overwriting previous content.\"\"\"\n",
        "    with open(out_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "        f.flush()\n",
        "        os.fsync(f.fileno())\n",
        "\n",
        "async def process_triple(triple, out_path: str):\n",
        "    img_name, prompt, meta_caption, img_path = triple\n",
        "    try:\n",
        "        json_result = await gveval_score_async(prompt, img_path, meta_caption)\n",
        "        record = {\n",
        "            \"image_name\": img_name,\n",
        "            \"result\": json.loads(json_result) if isinstance(json_result, str) else json_result\n",
        "        }\n",
        "        safe_append_jsonl(out_path, record)\n",
        "        print(f\"Saved: {img_name}\")\n",
        "        return record\n",
        "    except Exception as e:\n",
        "        print(f\"Error for {img_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "async def run_eval(triples, out_path: str):\n",
        "    sem = asyncio.Semaphore(CONCURRENT)\n",
        "    start_time = time.time()\n",
        "    completed = 0\n",
        "    results = []\n",
        "\n",
        "    total = len(triples)\n",
        "    for i, triple in enumerate(triples, start=1):\n",
        "        async with sem:\n",
        "            # enforce per-minute limit\n",
        "            elapsed = time.time() - start_time\n",
        "            if completed >= RPM and elapsed < 60:\n",
        "                await asyncio.sleep(60 - elapsed)\n",
        "                completed = 0\n",
        "                start_time = time.time()\n",
        "            completed += 1\n",
        "            rec = await process_triple(triple, out_path)\n",
        "            if rec:\n",
        "                results.append(rec)\n",
        "            # verbose progress\n",
        "            print(f\"[{i}/{total}] Processed image: {triple[0]} | Total saved: {len(results)}\")\n",
        "            if len(results) >= RPD:\n",
        "                print(\"Hit daily cap, stopping for today.\")\n",
        "                break\n",
        "    return results\n",
        "\n",
        "# --- Step 5: Load triples ---\n",
        "def load_triples(prompt_csv: str, meta_csv: str, image_folder: str):\n",
        "    df_prompts = pd.read_csv(prompt_csv)\n",
        "    df_meta = pd.read_csv(meta_csv)\n",
        "    triples = []\n",
        "    for _, row in df_meta.iterrows():\n",
        "        img_name = str(row[\"image_name\"]).strip()\n",
        "        prompt = row[\"Prompts\"]\n",
        "        meta_caption = row.get(\"Meta Caption\", \"\")\n",
        "        if not isinstance(meta_caption, str) or meta_caption.strip() == \"\":\n",
        "            continue\n",
        "        # find image\n",
        "        img_path = None\n",
        "        for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "            candidate = Path(image_folder) / f\"{img_name}{ext}\"\n",
        "            if candidate.exists():\n",
        "                img_path = candidate\n",
        "                break\n",
        "        if img_path is None:\n",
        "            continue\n",
        "        triples.append((img_name, prompt, meta_caption, img_path))\n",
        "    return triples\n",
        "\n",
        "# --- Step 6: Run for SDXL model ---\n",
        "base = \"/content/drive/MyDrive/gveval\"\n",
        "prompt_csv = f\"{base}/DrawBenchPrompts.csv\"\n",
        "meta_csv = f\"{base}/meta_captions_sdxl.csv\"\n",
        "image_folder = f\"{base}/sdxl\"\n",
        "out_file = f\"{base}/results_sdxl_gveval.jsonl\"\n",
        "\n",
        "# Prepare data\n",
        "triples = load_triples(prompt_csv, meta_csv, image_folder)\n",
        "print(f\"Loaded {len(triples)} triples.\")\n",
        "\n",
        "# Load already processed IDs and **filter triples before sending to GPT**\n",
        "done_ids = set()\n",
        "if Path(out_file).exists():\n",
        "    with open(out_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                rec = json.loads(line)\n",
        "                done_ids.add(rec[\"image_name\"])\n",
        "            except:\n",
        "                pass\n",
        "print(f\"Already done: {len(done_ids)}\")\n",
        "\n",
        "# Filter out already processed triples\n",
        "triples_to_process = [t for t in triples if t[0] not in done_ids]\n",
        "print(f\"Remaining images to process: {len(triples_to_process)}\")\n",
        "\n",
        "# Run evaluation (Colab-safe)\n",
        "loop = asyncio.get_event_loop()\n",
        "results = loop.run_until_complete(run_eval(triples_to_process, out_file))\n",
        "print(\"Evaluation completed.\")\n"
      ]
    }
  ]
}
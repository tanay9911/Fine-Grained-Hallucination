{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "C87juQt05nJR",
        "outputId": "ef209a0b-506f-42a8-d6c5-a20a74308fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\"test\": 5}\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# 1️ Configure your API key\n",
        "genai.configure(api_key=\"\")\n",
        "\n",
        "# 2️ Create a model handle (remote model on Google servers)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# 3️ Quick test with a tiny text prompt\n",
        "response = model.generate_content([{\"text\": \"Hello, can you give a short JSON response like {'test': 5}?\"}])\n",
        "\n",
        "# 4️ Print the response\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52qMDS19Q_V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "_ZY7FxINDWGi",
        "outputId": "904d7041-2913-44e0-838c-567d44e5b692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw response text:\n",
            "```json\n",
            "{\n",
            "  \"relevance\": 1,\n",
            "  \"color_accuracy\": 4,\n",
            "  \"shape_matching\": 5,\n",
            "  \"number_of_objects\": \"Correct\",\n",
            "  \"text_correctness\": 0,\n",
            "  \"positioning\": 5\n",
            "}\n",
            "```\n",
            "JSON parsing failed: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Gemini\n",
        "genai.configure(api_key=\"\")\n",
        "\n",
        "# Paths\n",
        "root = \"/content/drive/MyDrive/eval_images\"\n",
        "folder_name = \"Flux-Dev_drawbench_images\"\n",
        "image_index = 188\n",
        "baseline_file = \"/content/drive/MyDrive/DrawBenchPrompts.csv\"\n",
        "\n",
        "# Load baseline prompts\n",
        "baseline_df = pd.read_csv(baseline_file)\n",
        "baseline_prompt = baseline_df.loc[image_index, \"Prompts\"]\n",
        "\n",
        "# Get actual image name from CSV\n",
        "image_name = str(baseline_df.loc[image_index, \"image_name\"])  # Convert to string if not\n",
        "\n",
        "# Find image with any extension\n",
        "image_pattern = os.path.join(root, folder_name, f\"{image_name}.*\")\n",
        "image_files = glob.glob(image_pattern)\n",
        "if not image_files:\n",
        "    raise FileNotFoundError(f\"No image found for {image_name} in {folder_name}\")\n",
        "image_path = image_files[0]\n",
        "\n",
        "# Read image bytes\n",
        "with open(image_path, \"rb\") as f:\n",
        "    image_bytes = f.read()\n",
        "\n",
        "# Build updated evaluation prompt\n",
        "prompt = f\"\"\"\n",
        "You are a strict evaluator. Given a baseline text prompt and an image, judge if the image reflects the baseline.\n",
        "\n",
        "Rate each dimension on a scale of 0–5 (integers only):\n",
        "1. Relevance: Does the image content correspond to the baseline prompt?\n",
        "2. Color Accuracy: Are the colors in the image consistent with the baseline prompt?\n",
        "3. Shape Matching: Are the shapes of objects correct and recognizable with respect to baseline prompt?\n",
        "4. Number of Objects: Does the image contain the correct number of objects described in the baseline prompt If yes return Correct else Incorrect?\n",
        "5. Text Correctness: If the baseline prompt contains any text inside '' check whether the image contains that text or not, else return None?\n",
        "6. Positioning: Are the objects positioned as described in the baseline prompt?\n",
        "\n",
        "Respond strictly in JSON:\n",
        "{{\n",
        "  \"relevance\": X,\n",
        "  \"color_accuracy\": Y,\n",
        "  \"shape_matching\": Z,\n",
        "  \"number_of_objects\": A,\n",
        "  \"text_correctness\": B,\n",
        "  \"positioning\": C\n",
        "}}\n",
        "\n",
        "Baseline prompt: \"{baseline_prompt}\"\n",
        "\"\"\"\n",
        "\n",
        "# Load Gemini model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Generate evaluation\n",
        "response = model.generate_content([\n",
        "    prompt,\n",
        "    {\"mime_type\": \"image/jpeg\", \"data\": image_bytes}\n",
        "])\n",
        "\n",
        "# Print raw response first\n",
        "print(\"Raw response text:\")\n",
        "print(response.text)\n",
        "\n",
        "# Parse JSON\n",
        "try:\n",
        "    result = json.loads(response.text.strip())\n",
        "    result[\"index\"] = image_index\n",
        "    print(\"Parsed JSON result:\")\n",
        "    print(json.dumps(result, indent=4))\n",
        "except Exception as e:\n",
        "    print(\"JSON parsing failed:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

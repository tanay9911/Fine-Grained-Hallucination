{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUfABHEpUIZ",
        "outputId": "273f94a4-e3a0-43a7-86a2-9a98c10598a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgqf3TBpZpw",
        "outputId": "2bc1027e-0197-4af7-d506-3f46f391ded1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RcyDI9eo_sz",
        "outputId": "791e6385-9a2d-4586-f330-17a1b83f0b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating SPICE for Flux-Dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170/170 [00:01<00:00, 146.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPICE score for Flux-Dev: 0.1308\n",
            "Calculating SPICE for SDXL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 316.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPICE score for SDXL: 0.1034\n",
            "Calculating SPICE for SD2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 456.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPICE score for SD2: 0.0935\n",
            "SPICE scores saved to: /content/drive/MyDrive/csvs/spice_scores.json\n",
            "{'Flux-Dev': 0.1308033132278193, 'SDXL': 0.10341236130339217, 'SD2': 0.09354926999176799}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ===== Paths =====\n",
        "root_csv = \"/content/drive/MyDrive/csvs\"\n",
        "baseline_file = os.path.join(root_csv, \"DrawBenchPrompts.csv\")\n",
        "\n",
        "generated_files = {\n",
        "    \"Flux-Dev\": \"meta_captions_Flux-Dev.csv\",\n",
        "    \"SDXL\": \"meta_captions_sdxl.csv\",\n",
        "    \"SD2\": \"meta_captions_sd_2.csv\"\n",
        "}\n",
        "\n",
        "output_json = os.path.join(root_csv, \"spice_scores.json\")\n",
        "\n",
        "# ===== Load baseline prompts =====\n",
        "baseline_df = pd.read_csv(baseline_file)\n",
        "baseline_dict = dict(zip(baseline_df[\"image_name\"], baseline_df[\"Prompts\"]))\n",
        "\n",
        "# ===== Preprocessing =====\n",
        "def clean_text(text):\n",
        "    return str(text).lower().strip()\n",
        "\n",
        "# ===== SPICE-like F1 calculation =====\n",
        "def spice_score(ref, cand):\n",
        "    ref_tokens = [w for w, t in pos_tag(word_tokenize(ref)) if t.startswith((\"NN\", \"JJ\", \"VB\"))]\n",
        "    cand_tokens = [w for w, t in pos_tag(word_tokenize(cand)) if t.startswith((\"NN\", \"JJ\", \"VB\"))]\n",
        "\n",
        "    if not ref_tokens or not cand_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    overlap = set(ref_tokens) & set(cand_tokens)\n",
        "    precision = len(overlap) / len(cand_tokens)\n",
        "    recall = len(overlap) / len(ref_tokens)\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * precision * recall / (precision + recall)  # F1\n",
        "\n",
        "# ===== Compute for all models =====\n",
        "average_scores = {}\n",
        "\n",
        "for model_name, file_name in generated_files.items():\n",
        "    print(f\"Calculating SPICE for {model_name}...\")\n",
        "    file_path = os.path.join(root_csv, file_name)\n",
        "    df = pd.read_csv(file_path).dropna(subset=[\"Meta Caption\"])\n",
        "\n",
        "    scores = []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        image_id = row[\"image_name\"]\n",
        "        ref = baseline_dict.get(image_id)\n",
        "        cand = row[\"Meta Caption\"]\n",
        "        if ref and cand:\n",
        "            scores.append(spice_score(clean_text(ref), clean_text(cand)))\n",
        "\n",
        "    avg_score = sum(scores) / len(scores) if scores else 0.0\n",
        "    average_scores[model_name] = avg_score\n",
        "    print(f\"SPICE score for {model_name}: {avg_score:.4f}\")\n",
        "\n",
        "# ===== Save JSON =====\n",
        "with open(output_json, \"w\") as f:\n",
        "    json.dump(average_scores, f, indent=4)\n",
        "\n",
        "print(\"SPICE scores saved to:\", output_json)\n",
        "print(average_scores)\n"
      ]
    }
  ]
}